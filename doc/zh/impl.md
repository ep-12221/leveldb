## Files（文件）

> 注：本文是 `doc/impl.md` 的中文翻译；以英文原文为准。（2026-01-30）

leveldb 的实现精神上与单个 [Bigtable tablet（第 5.3 节）](https://research.google/pubs/pub27898/) 类似。不过，用于表示该 tablet 的文件组织方式略有不同，下面会解释。

每个数据库由存放在一个目录里的若干文件组成。按用途大体分为如下几类：

### Log files（日志文件）

日志文件（`*.log`）保存一系列最近的更新。每次更新都会追加到当前日志文件中。当日志文件达到预设大小（默认约 4MB）时，它会被转换为一个有序表（见下文），然后创建一个新的日志文件用于后续更新。

当前日志文件会在内存结构（`memtable`）中保留一份拷贝。每次读取都会查询这份拷贝，从而使读取能反映所有已写入日志的更新。

## Sorted tables（有序表）

有序表（`*.ldb`）保存一系列按 key 排序的条目。每个条目要么是该 key 的值，要么是该 key 的删除标记。（删除标记会保留一段时间，用于屏蔽旧的有序表中仍存在的过期值。）

有序表按层级（level）组织成一个序列。由日志文件生成的有序表会先放入一个特殊的“年轻层”（**young** level，也称 level-0）。当年轻层文件数量超过一定阈值（当前为 4）时，所有年轻层文件会与所有有重叠范围的 level-1 文件合并，生成一组新的 level-1 文件（我们会每 2MB 数据生成一个新的 level-1 文件）。

年轻层里的文件可能包含重叠的 key；但其他层（level-1 及以上）里的文件 key 范围是不重叠的。考虑层级 L（L >= 1）：当 level-L 的文件总大小超过其上限（`(10^L)` MB，即 level-1 为 10MB、level-2 为 100MB……）时，会从 level-L 选取一个文件，并与 level-(L+1) 中所有重叠的文件合并，生成一组新的 level-(L+1) 文件。这样的合并会逐步把新的更新从年轻层迁移到最大层，并且只使用批量读写（即尽量减少昂贵的 seek）。

### Manifest

MANIFEST 文件列出每一层中构成数据库的有序表集合、对应的 key 范围，以及其他重要元数据。每当数据库重新打开时都会创建一个新的 MANIFEST 文件（文件名中包含一个新的编号）。MANIFEST 文件的格式是日志（log），所有对“对外服务状态”（serving state）的更改（增加/删除文件）都会追加到这个日志中。

### Current

CURRENT 是一个简单的文本文件，包含最新 MANIFEST 文件的名字。

### Info logs（信息日志）

信息性消息会打印到名为 LOG 和 LOG.old 的文件中。

### Others（其他）

也可能会出现用于杂项目的的其他文件（LOCK、`*.dbtmp`）。

## Level 0

当日志文件增长到一定大小以上（默认 4MB）时：
创建一个全新的 memtable 和日志文件，并将之后的更新写入到这里。

在后台：

1. 将之前 memtable 的内容写成一个 sstable。
2. 丢弃旧 memtable。
3. 删除旧日志文件与旧 memtable。
4. 将新的 sstable 加入年轻层（level-0）。

## Compactions（压实/合并）

当 level L 的大小超过其限制时，我们会在后台线程对其进行 compaction。一次 compaction 会从 level L 选取一个文件，并选取下一层 level L+1 中所有与之重叠的文件。注意：如果 level-L 的某个文件只与 level-(L+1) 的某个文件部分重叠，那么 level-(L+1) 中的整个文件都会被作为 compaction 的输入，并在 compaction 后被丢弃。顺带一提：由于 level-0 很特殊（其中的文件彼此可能重叠），我们对从 level-0 到 level-1 的 compaction 做了特殊处理：一次 level-0 compaction 可能会选取多个 level-0 文件，以覆盖这些文件之间的重叠。

一次 compaction 会合并被选取文件的内容，生成一序列 level-(L+1) 文件。当当前输出文件达到目标文件大小（2MB）时，我们会切换到生成一个新的 level-(L+1) 文件。当前输出文件的 key 范围增长到足以与超过 10 个 level-(L+2) 文件产生重叠时，我们也会切换到新的输出文件。后一条规则能保证后续对 level-(L+1) 文件做 compaction 时，不会从 level-(L+2) 拉进太多数据。

旧文件会被丢弃，新文件会加入对外服务状态。

对某一层的 compaction 会在 key 空间上轮转。更具体地：对于每一层 L，我们记住该层上一次 compaction 的结束 key。下一次对 level L 的 compaction 会选择第一个起始 key 大于该结束 key 的文件（如果不存在则回绕到 key 空间开头）。

compaction 会丢弃被覆盖的值。如果当前 key 的范围在更高编号的层中不存在任何与之重叠的文件，则 compaction 也会丢弃对应的删除标记。

### Timing（耗时）

level-0 compaction 最多会从 level-0 读 4 个 1MB 文件，并且在最坏情况下还会读全部 level-1 文件（10MB）。也就是说，会读 14MB、写 14MB。

除 level-0 的特殊 compaction 之外，我们会从 level L 选取一个 2MB 文件。在最坏情况下，它会与 level L+1 的约 12 个文件重叠（因为 level-(L+1) 的大小是 level-L 的 10 倍，再加上边界处通常还有两个文件，因为 level-L 的文件范围通常不与 level-(L+1) 的文件范围对齐）。因此，该 compaction 会读 26MB、写 26MB。假设磁盘 IO 速率为 100MB/s（现代硬盘的大概范围），最坏情况下 compaction 成本约 0.5 秒。

如果我们将后台写入节流到较小值，比如满速 100MB/s 的 10%，一次 compaction 可能需要 5 秒。如果用户以 10MB/s 写入，我们可能会积累大量 level-0 文件（约 50 个，用来容纳 5*10MB）。这会因为每次读取都要合并更多文件，而显著增加读取成本。

方案 1：为减少这个问题，可以在 level-0 文件数量较大时提高日志切换阈值。缺点是阈值越大，需要更多内存来容纳对应的 memtable。

方案 2：在 level-0 文件数量增加时，人为降低写入速率。

方案 3：继续降低“极宽合并”的成本。也许多数 level-0 文件的 block 会以未压缩形式驻留在 cache 中，这样我们只需担心合并迭代器的 O(N) 复杂度。

### Number of files（文件数量）

与其总是生成 2MB 文件，不如对更高层生成更大的文件，以减少总文件数，但代价是 compaction 更“突发”。另一个选择是把文件集分片到多个目录。

在 ext3 文件系统上（2011-02-04）的一个实验显示：对不同文件数量的目录，打开 100K 个文件的耗时如下：

| 目录中文件数 | 打开一个文件的微秒数 |
|------------:|---------------------:|
|        1000 |                    9 |
|       10000 |                   10 |
|      100000 |                   16 |

所以在现代文件系统上，也许连分片都不需要？

## Recovery（恢复）

* 读取 CURRENT，得到最新已提交 MANIFEST 的名称
* 读取该 MANIFEST 文件
* 清理过期文件
* 这里可以打开所有 sstable，但最好还是延迟打开……
* 将日志 chunk 转换为一个新的 level-0 sstable
* 恢复后的写入会指向一个新的日志文件，并使用恢复出的 sequence#

## Garbage collection of files（文件垃圾回收）

`RemoveObsoleteFiles()` 会在每次 compaction 结束和恢复结束时被调用。它会列出数据库目录中所有文件名，并删除：

* 所有不是当前日志文件的日志文件
* 所有没有被任何 level 引用、且不是某个活跃 compaction 输出的 table 文件

